{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1060b949",
   "metadata": {},
   "source": [
    "# 한 시스템이 더 나은지 95% 확신하기 위해 필요한 평가 샘플 수에 대한 대략적인 추정치 \n",
    "\n",
    "- 감지할 차이 \n",
    "\n",
    "| 감지할 차이  | 95% 실뢰도에 대한 필요한 표본 크기 |\n",
    "|-----------|-----------------------------|\n",
    "| 30%       | ~ 10                        | \n",
    "| 10%       | ~ 100                       | \n",
    "| 3%        | ~ 10,00                     | \n",
    "| 1%        | ~ 10,000                    | \n",
    "\n",
    "\n",
    "> 오픈 AI는 점수 차이가 있을 때 한 시스템이 더 나은지 확신하기 위해 필요한 평가 샘플 수에 대한 대략적인 추정치를 제안했음. \n",
    "> 참고로, Eleuther 의 lm-evaluation-harness 평가 벤치 마크 중에서 예시의 중앙값은 1,000개이며, 평균은 2,159개다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d964d24f",
   "metadata": {},
   "source": [
    "# 평가 파이프라인 평가하기 \n",
    "\n",
    "### 평가 파이프라인이 올바른 신호를 제공하고 있는가?\n",
    "### 평가 파이프라인은 얼마나 신뢰할 수 있는가?\n",
    "### 지표간 상관관계는 어떠한가?\n",
    "### 평가 파이프라인이 애플리케이션에 얼마나 많은 비용과 지연시간을 추가하는가? "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
